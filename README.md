# ğŸ›¡ï¸ TrustNet (In Progress)

**TrustNet** is a full-stack AI-powered platform built to ensure product authenticity, detect fake reviews, and flag anomalies across the product lifecycle. Currently under active development, this system is designed to assist marketplaces in maintaining trust and safety at scale.

---

## ğŸ§  Project Background

TrustNet was originally conceptualized for **HackOn with Amazon - Season 5** under the theme **"AI-Powered Trust & Safety Platform."** Although it was not shortlisted for the next round, this repository reflects my ongoing effort to build the platform independently for learning and portfolio development.

ğŸ“ [View HackOn Pitch Deck Â»](./docs/HackOn_Presentation.pdf)

---

## ğŸš§ Current Status

> This project is a work in progress. Below is a breakdown of completed and pending modules.

### Core Functionality
- [x] Frontendâ€“backend architecture setup
- [x] RESTful APIs using Express + Mongoose
- [x] MongoDB schema for product/review system

### AI-Powered Features
- [x] ğŸ”— Fake review detection using Mistral-7B via LLM API
- [ ] ğŸ§  Counterfeit product detection using ResNet + metadata (planned)
- [ ] ğŸ“ˆ Timeline anomaly detection using Isolation Forest (planned)

### Moderator/Admin Panel
- [x] ğŸ›ï¸ Dashboard with filters (reviewer, product, classification)
- [x] ğŸ–Šï¸ Edit review classification (e.g., mark as â€œHuman Verifiedâ€)
- [x] ğŸ—‘ï¸ Delete flagged fake reviews
- [x] ğŸ“Š Pie chart breakdown: % of fake vs real reviews
- [x] âœ… Confirmation modals for sensitive actions
- [x] ğŸŒ€ Processing loader while awaiting LLM response

---

## ğŸ’¡ UI Enhancements

- Review classification visibly tagged as `Fake` (red badge)
- Real-time stats with interactive Recharts pie chart
- Toast/error feedback via console fallback
- Clean confirmation modals for edit/delete
- Loader spinner while review is analyzed by Mistral LLM

---

## ğŸ¤– LLM Integration

This project uses the **`mistral-7b-instruct-v0.2.Q4_K_M.gguf`** model for fake review classification, hosted locally using [`text-generation-webui`](https://github.com/oobabooga/text-generation-webui) with OpenAI-compatible API extensions.

The model analyzes reviews and responds with:
- `Classification`: Fake or Real  
- `Explanation`: Reasoning behind the decision

> ğŸ”§ *The LLM layer is modular and can later be fine-tuned or swapped for models like Zephyr or custom-distilled variants.*

## ğŸ”Œ LLM Server Setup

We use [`text-generation-webui`](https://github.com/oobabooga/text-generation-webui) to serve the Mistral model via OpenAI-style API endpoints.

### LLM API Endpoint
POST http://localhost:5001/v1/chat/completions

Make sure to launch it with:
```bash
python server.py --model mistral-7b-instruct-v0.2.Q4_K_M.gguf --api --nowebui --extensions openai --api-port 5001
```

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technologies                                     |
|--------------|--------------------------------------------------|
| Frontend     | React.js                                         |
| Backend      | Node.js, Express.js                              |
| Database     | MongoDB, Mongoose                                |
| AI Modules   | ResNet-50, DistilBERT, Isolation Forest (planned)|
| LLM Engine   | Mistral-7B via llama.cpp (OpenAI-compatible API) |

---

## ğŸ—‚ï¸ Project Structure

```bash
trustnet-ai/
â”œâ”€â”€ backend/               # Express backend
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ server.js
â”œâ”€â”€ docs/ 
â”‚   â””â”€â”€ HackOn_Presentation.pdf
â”œâ”€â”€ public/                # Frontend static assets
â”œâ”€â”€ src/                   # React frontend source
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸŒ Local Setup Instructions (Basic)

### Clone the repo-
git clone https://github.com/Nayan172005/trustnet-ai.git
cd trustnet-ai

### Install backend dependencies-
cd backend
npm install

### Install frontend dependencies-
cd ../
npm install

### Start MongoDB (if local)-
mongod

### Start LLM server (if mistral-7b is locally served)-
python server.py --model mistral-7b-instruct-v0.2.Q4_K_M.gguf --api --nowebui --extensions openai --api-port 5001

### Start backend-
cd backend
node server.js

### Start frontend-
cd ../
npm start
